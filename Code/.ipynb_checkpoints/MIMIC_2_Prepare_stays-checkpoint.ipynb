{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Prepare Stay Objects\n",
    "### Import libraries, set paths & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "from pandas.tslib import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set these as appropriate\n",
    "MIMIC_PATH = '/Users/Mark/Downloads/MIMIC Data/Original'\n",
    "VAR_BOUNDS_FILE = '/Users/Mark/Documents/GitHub/MIMIC-Machine-Learning/Reference Files/mimic3_variables.csv'\n",
    "OUTPUT_PATH = '/Users/Mark/Downloads/MIMIC Data/Processed_mini/Episodes'\n",
    "\n",
    "NB_ROWS_CHARTEVENTS = 263201376\n",
    "NB_ROWS_LABEVENTS = 27872576\n",
    "NB_ROWS_OUTPUTEVENTS = 4349340\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'diastolic blood pressure', 'systolic blood pressure', 'capillary refill rate binary', 'fraction inspired o2', 'glasgow coma scale total', 'glucose', 'heart rate', 'ph', 'respiratory rate', 'oxygen saturation', 'temperature', 'bilirubin', 'pco2', 'weight']\n"
     ]
    }
   ],
   "source": [
    "variables = ['diastolic blood pressure',\n",
    "           'systolic blood pressure',\n",
    "           'capillary refill rate binary',\n",
    "           'fraction inspired o2',\n",
    "           'glasgow coma scale total',\n",
    "           'glucose',\n",
    "           'heart rate',\n",
    "           'ph',\n",
    "           'respiratory rate',\n",
    "           'oxygen saturation',\n",
    "           'temperature',\n",
    "           'bilirubin',\n",
    "           'pco2',\n",
    "           'weight',\n",
    "           'height',\n",
    "           'gender',\n",
    "           'race' ]\n",
    "\n",
    "channels = variables[:-3]\n",
    "channels.insert(0, 'time')\n",
    "print(channels)\n",
    "\n",
    "var_bounds = DataFrame.from_csv(VAR_BOUNDS_FILE, index_col='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for value transformations, normalizations, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ETCO2: haven't found yet\n",
    "# Urine output: ambiguous units (raw ccs, ccs/kg/hr, 24-hr, etc.)\n",
    "# Tidal volume: tried to substitute for ETCO2 but units are ambiguous\n",
    "\n",
    "# SBP: some are strings of type SBP/DBP\n",
    "def transform_sbp(df):\n",
    "    v = df.VALUE.astype(str)\n",
    "    idx = v.apply(lambda s: '/' in s)\n",
    "    v[idx] = v[idx].apply(lambda s: re.match('^(\\d+)/(\\d+)$', s).group(1))\n",
    "    return v.astype(float)\n",
    "\n",
    "def transform_dbp(df):\n",
    "    v = df.VALUE.astype(str)\n",
    "    idx = v.apply(lambda s: '/' in s)\n",
    "    v[idx] = v[idx].apply(lambda s: re.match('^(\\d+)/(\\d+)$', s).group(2))\n",
    "    return v.astype(float)\n",
    "\n",
    "# CRR: strings with brisk, <3 normal, delayed, or >3 abnormal\n",
    "def transform_crr(df):\n",
    "    v = Series(np.zeros(df.shape[0]), index=df.index)\n",
    "    v[:] = np.nan\n",
    "    v[(df.VALUE == 'Normal <3 secs') | (df.VALUE == 'Brisk')] = 0\n",
    "    v[(df.VALUE == 'Abnormal >3 secs') | (df.VALUE == 'Delayed')] = 1\n",
    "    return v\n",
    "\n",
    "# FIO2: many 0s, some 0<x<0.2 or 1<x<20\n",
    "def transform_fio2(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'torr' not in s.lower()) & (v>1.0)\n",
    "    v[idx] = v[idx] / 100.\n",
    "    return v\n",
    "\n",
    "# GLUCOSE, PH: sometimes have ERROR as value\n",
    "def transform_lab(df):\n",
    "    v = df.VALUE\n",
    "    idx = v.apply(lambda s: type(s) is str and not re.match('^(\\d+(\\.\\d*)?|\\.\\d+)$', s))\n",
    "    v[idx] = np.nan\n",
    "    return v.astype(float)\n",
    "\n",
    "# O2SAT: small number of 0<x<=1 that should be mapped to 0-100 scale\n",
    "def transform_o2sat(df):\n",
    "#     v = df[df.VALUE.applymap(np.isreal).all(1)].VALUE.astype(float)\n",
    "    v = df.VALUE.astype(float)\n",
    "    idx = (v<=1)\n",
    "    v[idx] = v[idx] * 100.\n",
    "    return v\n",
    "\n",
    "# Temperature: map Farenheit to Celsius, some ambiguous 50<x<80\n",
    "def transform_temperature(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'F' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'F' in s.lower()) | (v >= 79)\n",
    "    v[idx] = (v[idx] - 32) * 5. / 9\n",
    "    return v\n",
    "\n",
    "# Weight: some really light/heavy adults: <50 lb, >450 lb, ambiguous oz/lb\n",
    "# Children are tough for height, weight\n",
    "def transform_weight(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    # ounces\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'oz' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'oz' in s.lower())\n",
    "    v[idx] = v[idx] / 16.\n",
    "    # pounds\n",
    "    idx = idx | df.VALUEUOM.fillna('').apply(lambda s: 'lb' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'lb' in s.lower())\n",
    "    v[idx] = v[idx] * 0.453592\n",
    "    return v\n",
    "\n",
    "# Height: some really short/tall adults: <2 ft, >7 ft)\n",
    "# Children are tough for height, weight\n",
    "def transform_height(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'in' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'in' in s.lower())\n",
    "    v[idx] = (v[idx] * 2.54).round()\n",
    "    return v\n",
    "\n",
    "var_transforms = {\n",
    "    'systolic blood pressure': transform_sbp,\n",
    "    'diastolic blood pressure': transform_dbp,\n",
    "    'capillary refill rate binary': transform_crr,\n",
    "    'fraction inspired o2': transform_fio2,\n",
    "    'glucose': transform_lab,\n",
    "    'ph': transform_lab,\n",
    "    'oxygen saturation': transform_o2sat,\n",
    "    'temperature': transform_temperature,\n",
    "    'weight': transform_weight,\n",
    "    'height': transform_height\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [SUBJECT_ID, HADM_ID, ICUSTAY_ID, CHARTTIME, VARIABLE, VALUE, VALUEUOM, MIMIC_LABEL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "dirs = glob.glob(os.path.join(OUTPUT_PATH, '*'))\n",
    "nb_dirs = len(dirs)\n",
    "for d_no, d in enumerate(dirs):\n",
    "    if not os.path.isdir(d):\n",
    "        continue   \n",
    "#     diags = DataFrame.from_csv(os.path.join(d, 'diagnoses.csv'), index_col=None, parse_dates=False).sort_values(by=['ICUSTAY_ID', 'SEQ_NUM']).set_index('ICUSTAY_ID')\n",
    "    obs = DataFrame.from_csv(os.path.join(d, 'observations.csv'), index_col=None, parse_dates=False)\n",
    "    obs.CHARTTIME = pd.to_datetime(obs.CHARTTIME)\n",
    "#     print(obs)\n",
    "    \n",
    "    obs2 = obs.ix[obs.VALUE.isnull()]\n",
    "#     print(obs2)\n",
    "    obs3= obs.ix[obs.VALUE.notnull()]\n",
    "    obs4 = obs3.ix[obs.VALUE.isnull()]\n",
    "    print(obs4)\n",
    "    \n",
    "#     # Transform values, remove outliers\n",
    "#     for vname in var_transforms.keys():\n",
    "#         if (obs.VARIABLE==vname).any():\n",
    "#             obs.VALUE[obs.VARIABLE==vname] = var_transforms[vname](obs.ix[obs.VARIABLE==vname])\n",
    "#             v = obs.VALUE[obs.VARIABLE==vname]\n",
    "#             v[v < var_bounds.dropBelow[vname]] = np.nan\n",
    "#             v[v < var_bounds.minValue[vname]]  = var_bounds.minValue[vname]\n",
    "#             v[v > var_bounds.dropAbove[vname]] = np.nan\n",
    "#             v[v > var_bounds.maxValue[vname]]  = var_bounds.maxValue[vname]\n",
    "#             obs.VALUE[obs.VARIABLE==vname] = v\n",
    "#     obs.VALUE = obs.VALUE.astype(float)\n",
    "#     obs = obs.ix[obs.VALUE.notnull()]\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT 663 of 1000 (514), STAY_ID 246326: 135 observations"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:4428: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'QNS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-50db9a358e78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_transforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVARIABLE\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mvname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVALUE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVARIABLE\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mvname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_transforms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVARIABLE\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mvname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVALUE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVARIABLE\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mvname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mvar_bounds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropBelow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-ea15581c8eca>\u001b[0m in \u001b[0;36mtransform_o2sat\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# O2SAT: small number of 0<x<=1 that should be mapped to 0-100 scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtransform_o2sat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVALUE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, **kwargs)\u001b[0m\n\u001b[0;32m   2945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2946\u001b[0m         mgr = self._data.astype(dtype=dtype, copy=copy,\n\u001b[1;32m-> 2947\u001b[1;33m                                 raise_on_error=raise_on_error, **kwargs)\n\u001b[0m\u001b[0;32m   2948\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   2871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2872\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2873\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2875\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2832\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2833\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, values, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m                **kwargs):\n\u001b[0;32m    421\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[1;32m--> 422\u001b[1;33m                             values=values, **kwargs)\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[1;32mC:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, raise_on_error, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mark\\Miniconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m   2629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'QNS'"
     ]
    }
   ],
   "source": [
    "S = []\n",
    "T = []\n",
    "\n",
    "patient_id = []\n",
    "admit_id = []\n",
    "episode_id = []\n",
    "encounter_no = []\n",
    "age = []\n",
    "race = []\n",
    "sex = []\n",
    "admit_diagnosis = []\n",
    "weight = []\n",
    "height = []\n",
    "\n",
    "ylos = []\n",
    "\n",
    "dirs = glob.glob(os.path.join(OUTPUT_PATH, '*'))\n",
    "nb_dirs = len(dirs)\n",
    "for d_no, d in enumerate(dirs):\n",
    "    if not os.path.isdir(d):\n",
    "        continue\n",
    "    # Every stays is patients records with multiple stays. Some may only have one row, stay, while others have many.\n",
    "    stays = DataFrame.from_csv(os.path.join(d, 'stays.csv'), index_col='ICUSTAY_ID', parse_dates=False).drop_duplicates()\n",
    "    stays.INTIME = pd.to_datetime(stays.INTIME)\n",
    "    stays.OUTTIME = pd.to_datetime(stays.OUTTIME)\n",
    "    stays.DEATHTIME = stays.DEATHTIME.apply(lambda s: pd.to_datetime(s) if type(s) is str or not np.isnan(s) else np.nan)\n",
    "    stays.sort_values(by='INTIME', inplace=True)\n",
    "#     diags = DataFrame.from_csv(os.path.join(d, 'diagnoses.csv'), index_col=None, parse_dates=False).sort_values(by=['ICUSTAY_ID', 'SEQ_NUM']).set_index('ICUSTAY_ID')\n",
    "    obs = DataFrame.from_csv(os.path.join(d, 'observations.csv'), index_col=None, parse_dates=False)\n",
    "    obs.CHARTTIME = pd.to_datetime(obs.CHARTTIME)\n",
    "    obs = obs.ix[obs.VALUE.notnull()]\n",
    "    \n",
    "    # Transform values, remove outliers\n",
    "    for vname in var_transforms.keys():\n",
    "        if (obs.VARIABLE==vname).any():\n",
    "            obs.VALUE[obs.VARIABLE==vname] = var_transforms[vname](obs.ix[obs.VARIABLE==vname])\n",
    "            v = obs.VALUE[obs.VARIABLE==vname]\n",
    "            v[v < var_bounds.dropBelow[vname]] = np.nan\n",
    "            v[v < var_bounds.minValue[vname]]  = var_bounds.minValue[vname]\n",
    "            v[v > var_bounds.dropAbove[vname]] = np.nan\n",
    "            v[v > var_bounds.maxValue[vname]]  = var_bounds.maxValue[vname]\n",
    "            obs.VALUE[obs.VARIABLE==vname] = v\n",
    "    obs.VALUE = obs.VALUE.astype(float)\n",
    "    obs = obs.ix[obs.VALUE.notnull()]\n",
    "    \n",
    "    # Check if \"after changes\" the observation is still valid.\n",
    "    if obs.shape[0] == 0:\n",
    "        sys.stdout.write('\\rSUBJECT {0} of {1} ({2}) has no data!'.format(d_no+1, nb_dirs, re.search('(\\d+)', d).group(1)))\n",
    "        continue\n",
    "    \n",
    "    #  For timestamped events, I say that it belongs to an ICU stay if *EITHER* it has that ICUSTAY_ID *OR* it falls between that ICU stay's INTIME and OUTTIME.\n",
    "    for stay_no, stay_id in enumerate(stays.index):\n",
    "        \n",
    "        # Find out rows, events, that fix the condtion. idx = valid rows, events, in obsevation file within single ICUSTAY.\n",
    "        idx = ((obs.CHARTTIME >= stays.INTIME[stay_id]) & (obs.CHARTTIME <= stays.OUTTIME[stay_id])) | (obs.ICUSTAY_ID == stay_id)\n",
    "        \n",
    "        # Find out if there are any stays that are totally empty\n",
    "        if not idx.any():\n",
    "            sys.stdout.write('\\rSUBJECT {0} of {1} ({2}), STAY_ID {3}: EMPTY!'.format(d_no+1, nb_dirs, stays.SUBJECT_ID[stay_id], stay_id))\n",
    "            continue\n",
    "        \n",
    "        # X is a data frame with all the variables, lab and event, recorded within single ICU stay\n",
    "        X = obs[['CHARTTIME', 'VARIABLE', 'VALUE']].ix[idx].sort_values(by='CHARTTIME').drop_duplicates(['CHARTTIME', 'VARIABLE'])\n",
    "        nb_obs = X.shape[0]\n",
    "        \n",
    "        # X is now a new matrix with fix row length, numbers of total variables or events. And index as timestamps\n",
    "        #            'diastolic blood pressure' 'systolic blood pressure' 'capillary refill rate' 'fraction inspired o2'......,\n",
    "        # 2100-12-23          100                           98                   23                          56 \n",
    "        # 1876-11-11          102                           94                   33                          46\n",
    "        #     ...             ...                           ...                 ...                          ..\n",
    "        X = X.pivot(index='CHARTTIME', columns='VARIABLE', values='VALUE').sort_index()\n",
    "        \n",
    "        ## Adding extra columns with column index as a variable that this patient originally deosn't have.\n",
    "        for c in variables:\n",
    "            if c not in X.columns:\n",
    "                X[c] = np.nan\n",
    "\n",
    "        try:\n",
    "            hours = (X.index.max() - X.index.min()).total_seconds()/60./60\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            if hours < 12:\n",
    "                sys.stdout.write('\\rSUBJECT {0} of {1} ({2}), STAY_ID {3}: <12 hours data'.format(d_no+1, nb_dirs, stays.SUBJECT_ID[stay_id], stay_id))\n",
    "                continue\n",
    "        \n",
    "        # Create lists with specific information\n",
    "        patient_id.append(stays.SUBJECT_ID[stay_id])\n",
    "        admit_id.append(stays.HADM_ID[stay_id])\n",
    "        episode_id.append(stay_id)\n",
    "        encounter_no.append(stay_no)\n",
    "        age.append(stays.AGE[stay_id])\n",
    "        race.append(stays.ETHNICITY[stay_id])\n",
    "        sex.append(stays.GENDER[stay_id])\n",
    "        admit_diagnosis.append(stays.DIAGNOSIS[stay_id])\n",
    "        weight.append(X.weight[X.weight.notnull()].iloc[0] if X.weight.notnull().any() else np.nan)\n",
    "        height.append(X.height[X.height.notnull()].iloc[0] if X.height.notnull().any() else np.nan)\n",
    "              \n",
    "        ylos.append(stays.LOS[stay_id])\n",
    "        \n",
    "        # Now, CHARTTIME, which used to be the index of X, becomes column[0]. Then change the name to \"time\"\n",
    "        X = X.reset_index().rename(columns={'CHARTTIME': 'time'})\n",
    "        \n",
    "        # Transform values in the column \"time\" from timestamps into length of time lapse, in minutes, relative to when the 1st event took place.\n",
    "        X.time = (X.time - X.time.min()) / np.timedelta64(1, 'm')\n",
    "        \n",
    "        # Select columns in X by 'channels' and transform it into 2D numpy.ndarray and append it to S. S becomes an 3D np.array\n",
    "        S.append(X[channels].values)\n",
    "        sys.stdout.write('\\rSUBJECT {0} of {1} ({2}), STAY_ID {3}: {4} observations'.format(d_no+1, nb_dirs, stays.SUBJECT_ID[stay_id], stay_id, nb_obs))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make every following lists contains only unique values\n",
    "admit_diagnoses = np.unique(admit_diagnosis)\n",
    "sex_categories = np.array(['M', 'F'])\n",
    "race_categories = np.unique(race)\n",
    "# diag_codes = DataFrame.from_csv(os.path.join(MIMIC_PATH, 'diagnostic_code_stats.csv'), index_col=None)\n",
    "# Yd_codes = diag_codes.ICD9_CODE.values.astype(str)\n",
    "\n",
    "# Transform all the list created above to numpy.ndarray\n",
    "patient_id = np.array(patient_id).astype(int)\n",
    "admit_id = np.array(admit_id).astype(int)\n",
    "episode_id = np.array(episode_id).astype(int)\n",
    "encounter_no = np.array(encounter_no).astype(int)\n",
    "age = np.array(age)\n",
    "\n",
    "########################## Don't understand the following lines\n",
    "race = (np.array(race)[:,None] == race_categories[None,:]).astype('int8')\n",
    "sex = (np.array(sex)[:,None] == sex_categories[None,:]).astype('int8')\n",
    "admit_diagnosis = (np.array(admit_diagnosis)[:,None] == admit_diagnoses[None,:]).astype('int8')\n",
    "\n",
    "########################## What don't cast the following lists into 'int' or 'float'?\n",
    "weight = np.array(weight)\n",
    "height = np.array(height)\n",
    "\n",
    "# Yd = np.vstack([ (np.array(yd).astype(str)[:,None] == Yd_codes).any(axis=0) for yd in Yd ]).astype('int8')\n",
    "# ymort = np.array(ymort).astype('int8')\n",
    "ylos = np.array(ylos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.07005047798156738\n",
      "Took 0.06905841827392578\n"
     ]
    }
   ],
   "source": [
    "# Save these into numpy.ndarray file format\n",
    "fns = [ os.path.join(OUTPUT_PATH, 'mimic3_12-NO_TIME_SERIES.npz'),\n",
    "        os.path.join(OUTPUT_PATH, 'mimic3_12.npz') ]\n",
    "sequences = [ [], S ]\n",
    "for fn, seq in zip(fns, sequences):\n",
    "    st = time.time()\n",
    "    \n",
    "    # Save two files. 1: Multiple arrays with the time series data, 3D array. 2: With 3D time series array\n",
    "    # Parameter: (fn = ouptput path, A=a, B=b, .....). A,B: Achrived name, a,b: array name \n",
    "    np.savez(fn,X=seq,\n",
    "                episode_id=episode_id,\n",
    "                admit_id=admit_id,\n",
    "                patient_id=patient_id,\n",
    "                encounter_no=encounter_no,\n",
    "                age=age,\n",
    "                race=race,\n",
    "                sex=sex,\n",
    "                admit_diagnosis=admit_diagnosis,\n",
    "                ylos=ylos,\n",
    "                race_categories=race_categories,\n",
    "                sex_categories=sex_categories,\n",
    "                admit_diagnoses=admit_diagnoses,\n",
    "                X_names=channels)\n",
    "    print('Took', time.time()-st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
